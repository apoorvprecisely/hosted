---
volumes:
  gluetun-tmp:
  ollama-data:
  open-webui-data:
  llama-models:

services:
  gluetun:
    image: qmcgaw/gluetun
    container_name: gluetun
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun:/dev/net/tun
    environment:
      - VPN_SERVICE_PROVIDER=protonvpn
      - OPENVPN_USER=wc1BWbyhqcUe1ICd+pmp
      - OPENVPN_PASSWORD=WqoGmKv28VVwwFNZyjoGydwzqo2dnSv4
      - SERVER_COUNTRIES=Singapore
      - FREE_ONLY=off
      - VPN_PORT_FORWARDING=on
      - VPN_PORT_FORWARDING_PROVIDER=protonvpn
    volumes:
      - gluetun-tmp:/tmp/gluetun  # Shared temp directory for port forwarding
    ports:
      - 8080:8080
      - 55705:55705
      - 55705:55705/udp
      - 9696:9696
      - 8989:8989
      - 5055:5055
      - 7878:7878
    restart: unless-stopped

  qbittorrent:
    image: lscr.io/linuxserver/qbittorrent:latest
    container_name: qbittorrent
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - WEBUI_PORT=8080
    volumes:
      - /home/apoorv/hosted/qbittorrent/appdata:/config
      - /media/apoorv/561DA19B02F15670/Downloads:/downloads
    restart: unless-stopped
    depends_on:
      - gluetun
    network_mode: "service:gluetun"

  # Service to sync Gluetun's forwarded port with qBittorrent
  port-sync:
    build:
      context: .
      dockerfile: Dockerfile.port-sync
    container_name: gluetun-qbittorrent-port-sync
    environment:
      - QBITTORRENT_HOST=localhost
      - QBITTORRENT_PORT=8080
      - QBITTORRENT_USER=apoorv
      - QBITTORRENT_PASS=clockwork
      - PORT_FILE=/tmp/gluetun/forwarded_port
      - CHECK_INTERVAL=30
    volumes:
      - gluetun-tmp:/tmp/gluetun:ro  # Mount Gluetun's temp directory
    depends_on:
      - gluetun
      - qbittorrent
    network_mode: "service:gluetun"
    restart: unless-stopped

  sonarr:
    image: lscr.io/linuxserver/sonarr:latest
    container_name: sonarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - /home/apoorv/hosted/sonarr:/config
      - /media/apoorv/561DA19B02F15670/Downloads:/downloads
    restart: unless-stopped
    depends_on:
      - gluetun
    network_mode: "service:gluetun"

  radarr:
    image: lscr.io/linuxserver/radarr:latest
    container_name: radarr
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - /home/apoorv/hosted/radarr:/config
      - /media/apoorv/561DA19B02F15670/Downloads:/downloads
    restart: unless-stopped
    depends_on:
      - gluetun
    network_mode: "service:gluetun"
  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jellyfin
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - JELLYFIN_PublishedServerUrl=http://192.168.1.14:8096
    volumes:
      - /home/apoorv/hosted/jellyfin/config:/config
      - /media/apoorv/561DA19B02F15670/Downloads:/downloads
      - /media/apoorv/561DA19B02F15670/letterboxd:/letterboxd
    ports:
      - 8096:8096
      - 8920:8920
      - 7359:7359/udp
      - 1900:1900/udp
    restart: unless-stopped
  prowlarr:
    container_name: prowlarr
    image: lscr.io/linuxserver/prowlarr:latest
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - /home/apoorv/hosted/prowlarr/config:/config
      - /home/apoorv/hosted/prowlarr/Custom:/config/Definitions/Custom
    restart: unless-stopped
    depends_on:
      - gluetun
    network_mode: "service:gluetun"

  filebrowser:
    image: filebrowser/filebrowser:latest
    container_name: filebrowser
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - /home/apoorv/hosted/filebrowser:/config
      - /media/apoorv/561DA19B02F15670/Downloads:/srv/downloads
      - /media/apoorv/561DA19B02F15670/letterboxd:/srv/letterboxd
      - /home/apoorv/hosted:/srv/config
    ports:
      - 8001:80
    restart: unless-stopped
    command: --noauth

  dockerproxy:
    image: ghcr.io/tecnativa/docker-socket-proxy:latest
    container_name: dockerproxy
    environment:
      - CONTAINERS=1
      - POST=0
    ports:
      - 127.0.0.1:2375:2375
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped

  homepage:
    image: ghcr.io/gethomepage/homepage:latest
    container_name: homepage
    environment:
      - PUID=1000
      - PGID=1000
      - HOMEPAGE_ALLOWED_HOSTS=192.168.1.14:3000,100.118.160.128:3000,localhost:3000
      - HOMEPAGE_VAR_HOST=192.168.1.14
      - HOMEPAGE_VAR_SONARR_KEY=00ac047b135443c38ae58bc39d46750d
      - HOMEPAGE_VAR_RADARR_KEY=14aa18947c5d4219ba8973d3d0f8a3bb
      - HOMEPAGE_VAR_PROWLARR_KEY=6de53eb56bb54e199a3b269425ce9a0a
      - HOMEPAGE_VAR_JELLYFIN_KEY=60ea486eb0aa4c7a918dc558aac80ca7
      - HOMEPAGE_VAR_QBITTORRENT_USERNAME=apoorv
      - HOMEPAGE_VAR_QBITTORRENT_PASSWORD=adminadmin
    volumes:
      - /home/apoorv/hosted/homepage:/app/config
    ports:
      - 3000:3000
    restart: unless-stopped
    depends_on:
      - dockerproxy

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - 11434:11434
    volumes:
      - ollama-data:/root/.ollama
    devices:
      - /dev/dri
    environment:
      - OLLAMA_LLM_LIBRARY=vulkan
      - GGML_VK_VISIBLE_DEVICES=0
      - OLLAMA_NUM_GPU=1
      - OLLAMA_NEW_ENGINE=true
    restart: unless-stopped

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OPENAI_API_BASE_URL=http://llamacpp:8080/v1
      - OPENAI_API_KEY=sk-local
      - WEBUI_AUTH=false
    ports:
      - 8090:8080
    volumes:
      - open-webui-data:/app/backend/data
    depends_on:
      - ollama
      - llamacpp
    restart: unless-stopped

  llamacpp:
    build:
      context: .
      dockerfile: Dockerfile.llamacpp
    container_name: llamacpp
    devices:
      - /dev/dri
    environment:
      - GGML_VK_VISIBLE_DEVICES=0
      - LLAMA_GPU_LAYERS=10
      - LLAMA_MODEL_URL=https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf
      - LLAMA_MODEL_PATH=/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
    volumes:
      - llama-models:/models
    ports:
      - 8003:8080
    restart: unless-stopped
