---
volumes:
  ollama-data:
  open-webui-data:
  llama-models:

services:
  transmission-openvpn:
    image: haugene/transmission-openvpn:latest
    container_name: transmission-openvpn
    network_mode: host
    cap_add:
      - NET_ADMIN
    devices:
      - /dev/net/tun
    environment:
      - OPENVPN_PROVIDER=PROTONVPN
      - OPENVPN_USERNAME=wc1BWbyhqcUe1ICd+pmp
      - OPENVPN_PASSWORD=WqoGmKv28VVwwFNZyjoGydwzqo2dnSv4
      - OPENVPN_CONFIG=sg.protonvpn.tcp
      - LOCAL_NETWORK=192.168.1.0/24,100.64.0.0/10
      - TRANSMISSION_WEB_UI=flood
      - PUID=1000
      - PGID=1000
    volumes:
      - /home/apoorv/hosted/transmission:/data
      - /mnt/1BB69A1109DD1CCD/Downloads:/downloads
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"

  qbittorrent:
    image: lscr.io/linuxserver/qbittorrent:latest
    container_name: qbittorrent
    network_mode: host
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - WEBUI_PORT=8080
      - DOCKER_MODS=ghcr.io/gabe565/linuxserver-mod-vuetorrent
    volumes:
      - /home/apoorv/hosted/qbittorrent/appdata:/config
      - /mnt/1BB69A1109DD1CCD/Downloads:/downloads
    depends_on:
      - transmission-openvpn
    restart: unless-stopped

  port-sync:
    build:
      context: .
      dockerfile: Dockerfile.port-sync
    container_name: protonvpn-qbittorrent-port-sync
    network_mode: host
    environment:
      - QBITTORRENT_HOST=localhost
      - QBITTORRENT_PORT=8080
      - QBITTORRENT_USER=admin
      - QBITTORRENT_PASS=adminadmin
      - CHECK_INTERVAL=60
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - transmission-openvpn
      - qbittorrent
    restart: unless-stopped

 
  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jellyfin
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
      - JELLYFIN_PublishedServerUrl=http://192.168.1.14:8096
    volumes:
      - /home/apoorv/hosted/jellyfin/config:/config
      - /mnt/1BB69A1109DD1CCD/Downloads:/downloads
      - /mnt/1BB69A1109DD1CCD/letterboxd:/letterboxd
    ports:
      - 8096:8096
      - 8920:8920
      - 7359:7359/udp
      - 1900:1900/udp
    restart: unless-stopped
  prowlarr:
    container_name: prowlarr
    image: lscr.io/linuxserver/prowlarr:latest
    network_mode: host
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - /home/apoorv/hosted/prowlarr/config:/config
      - /home/apoorv/hosted/prowlarr/Custom:/config/Definitions/Custom
    depends_on:
      - transmission-openvpn
    restart: unless-stopped

  filebrowser:
    image: filebrowser/filebrowser:latest
    container_name: filebrowser
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - /home/apoorv/hosted/filebrowser:/config
      - /mnt/1BB69A1109DD1CCD/Downloads:/srv/downloads
      - /mnt/1BB69A1109DD1CCD/letterboxd:/srv/letterboxd
      - /home/apoorv/hosted:/srv/config
    ports:
      - 8001:80
    restart: unless-stopped
    command: --noauth

  dockerproxy:
    image: ghcr.io/tecnativa/docker-socket-proxy:latest
    container_name: dockerproxy
    environment:
      - CONTAINERS=1
      - POST=0
    ports:
      - 127.0.0.1:2375:2375
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    restart: unless-stopped

  homepage:
    image: ghcr.io/gethomepage/homepage:latest
    container_name: homepage
    environment:
      - PUID=1000
      - PGID=1000
      - HOMEPAGE_ALLOWED_HOSTS=192.168.1.14:3000,100.118.160.128:3000,localhost:3000
      - HOMEPAGE_VAR_HOST=192.168.1.14
      - HOMEPAGE_VAR_SONARR_KEY=00ac047b135443c38ae58bc39d46750d
      - HOMEPAGE_VAR_RADARR_KEY=14aa18947c5d4219ba8973d3d0f8a3bb
      - HOMEPAGE_VAR_PROWLARR_KEY=6de53eb56bb54e199a3b269425ce9a0a
      - HOMEPAGE_VAR_JELLYFIN_KEY=60ea486eb0aa4c7a918dc558aac80ca7
      - HOMEPAGE_VAR_QBITTORRENT_USERNAME=apoorv
      - HOMEPAGE_VAR_QBITTORRENT_PASSWORD=adminadmin
    volumes:
      - /home/apoorv/hosted/homepage:/app/config
    ports:
      - 3000:3000
    restart: unless-stopped
    depends_on:
      - dockerproxy

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - 11434:11434
    volumes:
      - ollama-data:/root/.ollama
    devices:
      - /dev/dri
    environment:
      - OLLAMA_LLM_LIBRARY=vulkan
      - GGML_VK_VISIBLE_DEVICES=0
      - OLLAMA_NUM_GPU=1
      - OLLAMA_NEW_ENGINE=true
    restart: unless-stopped

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OPENAI_API_BASE_URL=http://llamacpp:8080/v1
      - OPENAI_API_KEY=sk-local
      - WEBUI_AUTH=false
    ports:
      - 8090:8080
    volumes:
      - open-webui-data:/app/backend/data
    depends_on:
      - ollama
      - llamacpp
    restart: unless-stopped

  llamacpp:
    build:
      context: .
      dockerfile: Dockerfile.llamacpp
    container_name: llamacpp
    devices:
      - /dev/dri
    environment:
      - GGML_VK_VISIBLE_DEVICES=0
      - LLAMA_GPU_LAYERS=10
      - LLAMA_MODEL_URL=https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf
      - LLAMA_MODEL_PATH=/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf
    volumes:
      - llama-models:/models
    ports:
      - 8003:8080
    restart: unless-stopped
